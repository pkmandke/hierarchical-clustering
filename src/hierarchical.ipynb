{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pkmandke/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/pkmandke/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting clustering...\n",
      "Done training in 0:00:01.805823s\n",
      "Time taken 2 days, 17:09:29.201184s\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "tfidf_obj = joblib.load('../obj/TFIDF_2.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_obj.tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(subdocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdocs[subdocs !=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tfidf_obj.doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agglo_clus import Agglo_clus as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_obj = ag(tfidf_obj.tfidf_matrix[:200, :].todense(), doc_names = tfidf_obj.doc_list[:200], num_clus = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_obj.clusterize()\n",
    "ag_obj.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe = pd.read_json('../data/30Kmetadata.json', orient=str, lines=True)[['identifier-uri',\\\n",
    "                                                                           'contributor-department', 'searchTitle']]\n",
    "clust = joblib.load('../obj/agglo_clus/iter_1/abstracts_etd_doc2vec_5000_docs_ag_clus.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setify(depts):\n",
    "    unq = []\n",
    "    for st in depts:\n",
    "        if st in unq:\n",
    "            continue\n",
    "        unq.append(st)\n",
    "    return unq\n",
    "\n",
    "def get_unique_field(df, field):\n",
    "    \n",
    "    return setify(df[field])\n",
    "\n",
    "def find_docs_in_cluster(df, idx, clust):\n",
    "    \n",
    "    return df.loc[df['identifier-uri'].isin([clust.doc_names[_] for _ in idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [idx for idx, _ in enumerate(clust.predictions) if _ == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Electrical and Computer Engineering ',\n",
       " 'Mechanical Engineering ',\n",
       " 'Aerospace and Ocean Engineering ',\n",
       " 'Mining and Minerals Engineering ',\n",
       " 'Urban Affairs and Planning ',\n",
       " 'Power Electronics Systems ',\n",
       " 'Architecture ',\n",
       " 'Electrical Engineering ',\n",
       " 'Materials Science and Engineering ',\n",
       " 'Biological Systems Engineering ',\n",
       " 'Civil Engineering ',\n",
       " 'Computer Science ',\n",
       " 'Engineering Science and Mechanics ',\n",
       " 'Industrial and Systems Engineering ',\n",
       " 'Chemistry ',\n",
       " 'Chemical Engineering ']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clust.doc_names[304]\n",
    "pd.options.display.max_rows = 5002\n",
    "depts = [_ for _ in dframe['contributor-department']]\n",
    "\n",
    "get_unique_field(find_docs_in_cluster(dframe, idx, clust), 'contributor-department')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(880,)\n",
      "(481,)\n",
      "(1001,)\n",
      "(1015,)\n",
      "(443,)\n",
      "(150,)\n",
      "(314,)\n",
      "(245,)\n",
      "(227,)\n",
      "(211,)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(clust.predictions[clust.predictions == _].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to generate small clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = gensim.models.doc2vec.Doc2Vec.load('../obj/doc2vec/abstracts_etd_doc2vec_5000_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pre_process import Doc2vec_wrapper, extract_mapped_doc2vecs\n",
    "\n",
    "doc_vectors, keys = extract_mapped_doc2vecs(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting clustering...\n",
      "Done training in 0:00:01.570734s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ag_model = ag(doc_vectors, doc_names = keys, num_clus = 100, linkage='ward', affinity='euclidean', iter_='1')\n",
    "\n",
    "ag_model.clusterize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76,\n",
       " 24,\n",
       " 47,\n",
       " 38,\n",
       " 50,\n",
       " 23,\n",
       " 19,\n",
       " 41,\n",
       " 82,\n",
       " 30,\n",
       " 55,\n",
       " 21,\n",
       " 10,\n",
       " 14,\n",
       " 65,\n",
       " 31,\n",
       " 25,\n",
       " 38,\n",
       " 15,\n",
       " 136,\n",
       " 36,\n",
       " 50,\n",
       " 132,\n",
       " 68,\n",
       " 40,\n",
       " 32,\n",
       " 108,\n",
       " 101,\n",
       " 47,\n",
       " 51,\n",
       " 59,\n",
       " 159,\n",
       " 27,\n",
       " 96,\n",
       " 37,\n",
       " 95,\n",
       " 61,\n",
       " 62,\n",
       " 38,\n",
       " 46,\n",
       " 20,\n",
       " 10,\n",
       " 115,\n",
       " 79,\n",
       " 60,\n",
       " 51,\n",
       " 56,\n",
       " 29,\n",
       " 57,\n",
       " 5,\n",
       " 45,\n",
       " 60,\n",
       " 18,\n",
       " 7,\n",
       " 123,\n",
       " 49,\n",
       " 13,\n",
       " 47,\n",
       " 11,\n",
       " 69,\n",
       " 114,\n",
       " 67,\n",
       " 23,\n",
       " 14,\n",
       " 79,\n",
       " 15,\n",
       " 82,\n",
       " 7,\n",
       " 118,\n",
       " 35,\n",
       " 1,\n",
       " 11,\n",
       " 54,\n",
       " 3,\n",
       " 57,\n",
       " 343,\n",
       " 28,\n",
       " 13,\n",
       " 64,\n",
       " 15,\n",
       " 7,\n",
       " 45,\n",
       " 1,\n",
       " 44,\n",
       " 40,\n",
       " 12,\n",
       " 52,\n",
       " 59,\n",
       " 66,\n",
       " 9,\n",
       " 49,\n",
       " 48,\n",
       " 6,\n",
       " 65,\n",
       " 79,\n",
       " 13,\n",
       " 71,\n",
       " 15,\n",
       " 21,\n",
       " 13]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(ag_model.predictions[ag_model.predictions == i]) for i in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    print(tfidf_obj.tfidf_matrix[_, :][tfidf_obj.tfidf_matrix[_, :] != 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = gensim.models.doc2vec.Doc2Vec.load('../obj/abstracts_etd_doc2vec_5000_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(1):\n",
    "    inferred_vector = m1.infer_vector(['a', 'b', 'c', 'd'])\n",
    "    sims = m1.docvecs.most_similar([inferred_vector], topn=len(m1.docvecs))\n",
    "    print(len(sims))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.docvecs['http://hdl.handle.net/10919/31250 ']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
